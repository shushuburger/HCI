import requests
import pandas as pd
import time
import os
from datetime import datetime

# ì¸ì½”ë”©ëœ API í‚¤
API_KEY = "MNUICj9LF0yMX9b9cMQiBVz62JWYaqaGxBOIATmwvQgzkfdHQjzCouGaBLIzyg6MYGQOHqefVCRf3E23XoqVGA%3D%3D"

# ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

STATION_LIST_FILE = os.path.join(DATA_DIR, "ì¸¡ì •ì†Œ_ëª©ë¡.xlsx")
CSV_FILE = os.path.join(DATA_DIR, "ìš¸ì‚°_ë¯¸ì„¸ë¨¼ì§€_ë°ì´í„°.csv")
XLSX_FILE = os.path.join(DATA_DIR, "ìš¸ì‚°_ë¯¸ì„¸ë¨¼ì§€_ë°ì´í„°.xlsx")

# ìš¸ì‚° ì¸¡ì •ì†Œë§Œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_ulsan_stations():
    try:
        df = pd.read_excel(STATION_LIST_FILE)
        ulsan_df = df[df["addr"].str.contains("ìš¸ì‚°")]
        return ulsan_df["stationName"].dropna().unique().tolist()
    except Exception as e:
        print("âŒ ì¸¡ì •ì†Œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:", e)
        return []

# ë¯¸ì„¸ë¨¼ì§€ ë°ì´í„° ìˆ˜ì§‘
def fetch_dust_data(stations):
    results = []
    for station in stations:
        encoded_station = requests.utils.quote(station, safe='')
        url = (
            f"http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty"
            f"?serviceKey={API_KEY}"
            f"&returnType=json"
            f"&numOfRows=1"
            f"&pageNo=1"
            f"&stationName={encoded_station}"
            f"&dataTerm=DAILY"
            f"&ver=1.0"
        )
        try:
            res = requests.get(url, timeout=5)
            if res.status_code != 200 or not res.text.strip():
                raise ValueError("ì‘ë‹µ ì—†ìŒ ë˜ëŠ” ìƒíƒœ ì˜¤ë¥˜")

            data = res.json()
            items = data.get("response", {}).get("body", {}).get("items", [])
            if not items:
                raise ValueError("ë°ì´í„° ì—†ìŒ")

            item = items[0]
            results.append({
                "ìˆ˜ì§‘ì‹œê°": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "ì¸¡ì •ì‹œê°": item.get("dataTime", ""),
                "ì¸¡ì •ì†Œ": station,
                "PM10": item.get("pm10Value", ""),
                "PM2.5": item.get("pm25Value", ""),
                "í†µí•©ì§€ìˆ˜": item.get("khaiValue", ""),
                "ì˜¤ì¡´": item.get("o3Value", ""),
                "ì´ì‚°í™”ì§ˆì†Œ": item.get("no2Value", ""),
                "ì¼ì‚°í™”íƒ„ì†Œ": item.get("coValue", ""),
                "ì•„í™©ì‚°ê°€ìŠ¤": item.get("so2Value", "")
            })
        except Exception as e:
            print(f"âš ï¸ {station} ì˜¤ë¥˜: {e}")
        time.sleep(0.5)  # ìš¸ì‚°ì€ ì¸¡ì •ì†Œ ìˆ˜ê°€ ì ìœ¼ë‹ˆ 0.5ì´ˆë¡œ ì—¬ìœ ìˆê²Œ
    return pd.DataFrame(results)

# ì €ì¥
def append_and_save(new_df):
    if os.path.exists(CSV_FILE):
        existing_df = pd.read_csv(CSV_FILE)
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = new_df

    combined_df.to_csv(CSV_FILE, index=False, encoding="utf-8-sig")
    combined_df.to_excel(XLSX_FILE, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {len(new_df)}ê°œ í•­ëª©")

# ì‹¤í–‰
if __name__ == "__main__":
    stations = load_ulsan_stations()
    print(f"ğŸ“ ìš¸ì‚° ì¸¡ì •ì†Œ ìˆ˜: {len(stations)}ê°œ")

    new_data = fetch_dust_data(stations)

    if not new_data.empty:
        append_and_save(new_data)
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
